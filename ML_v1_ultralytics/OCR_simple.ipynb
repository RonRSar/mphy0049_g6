{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# # Load model\n",
    "\n",
    "# model = YOLO(\"yolov8n.yaml\") #new model\n",
    "# model = YOLO(\"yolov8n.pt\") #pretrained model\n",
    "\n",
    "\n",
    "# # Use the model\n",
    "# model.train(data=\"coco128.yaml\", epochs=3)  # train the model\n",
    "# metrics = model.val()  # evaluate model performance on the validation set\n",
    "# results = model(\"https://ultralytics.com/images/bus.jpg\")  # predict on an image\n",
    "# path = model.export(format=\"onnx\")  # export the model to ONNX format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "vid = cv2.VideoCapture(0)\n",
    "\n",
    "while (True):\n",
    "    #frame capture\n",
    "    ret, frame = vid.read()\n",
    "\n",
    "    #display fra,e\n",
    "    cv2.imshow('Camera', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'test_text.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# pytesseract.pytesseract.tesseract_cmd = 'System_path_to_tesseract.exe'\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest_text.jpg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m text \u001b[38;5;241m=\u001b[39m pytesseract\u001b[38;5;241m.\u001b[39mimage_to_string(file)\n\u001b[0;32m      7\u001b[0m org \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m50\u001b[39m,\u001b[38;5;241m50\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ronit\\anaconda3\\envs\\mphy0049\\lib\\site-packages\\ultralytics\\utils\\patches.py:26\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(filename, flags)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimread\u001b[39m(filename: \u001b[38;5;28mstr\u001b[39m, flags: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mIMREAD_COLOR):\n\u001b[0;32m     16\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m    Read an image from a file.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;124;03m        (np.ndarray): The read image.\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mimdecode(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint8\u001b[49m\u001b[43m)\u001b[49m, flags)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test_text.jpg'"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "import cv2\n",
    "# pytesseract.pytesseract.tesseract_cmd = 'System_path_to_tesseract.exe'\n",
    "\n",
    "file = cv2.imread(\"test_text.jpg\")\n",
    "text = pytesseract.image_to_string(file)\n",
    "org = (50,50)\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "fontscale = 1\n",
    "color = (255,0,0)\n",
    "thickness = 2\n",
    "file = cv2.putText(file,text,org, font, fontscale, color, thickness, cv2.LINE_AA)\n",
    "cv2.imshow('image', file)\n",
    "while True: \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "import cv2\n",
    "\n",
    "vid = cv2.VideoCapture(0)\n",
    "\n",
    "hold = 'Start'\n",
    "while (True):\n",
    "    #frame capture\n",
    "    ret, frame = vid.read()\n",
    "\n",
    "    #frame read\n",
    "    text = pytesseract.image_to_string(frame)\n",
    "\n",
    "    #if text is coherent, hold it \n",
    "    if len(text) > 5:\n",
    "        hold = text\n",
    "\n",
    "    #display frame\n",
    "    cv2.putText(frame, hold, (50,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,225,0), 2, cv2.LINE_AA)\n",
    "    cv2.imshow('Camera', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "import cv2\n",
    "\n",
    "vid = cv2.VideoCapture(0)\n",
    "\n",
    "hold = 'Start'\n",
    "while (True):\n",
    "    #frame capture\n",
    "    ret, frame = vid.read()\n",
    "\n",
    "    #blurring & filtering\n",
    "    blur = cv2.GaussianBlur(frame, (5,5), 0)\n",
    "    grayimage = cv2.cvtColor(blur,cv2.COLOR_BGR2GRAY)\n",
    "    contrast = cv2.convertScaleAbs(grayimage, alpha = 2.0, beta = 0) #a = 1-3, b=0-100\n",
    "\n",
    "    out_frame = contrast\n",
    "\n",
    "    #frame read\n",
    "    cv2.rectangle(out_frame, (150,100),(300+200,100+300),(0,0,255),1)\n",
    "    text = pytesseract.image_to_string(out_frame[150:500,100:400])\n",
    "\n",
    "    #if text is coherent, hold it \n",
    "    if len(text) > 5:\n",
    "        hold = text\n",
    "        boxes = pytesseract.image_to_data(out_frame, output_type=pytesseract.Output.DICT)\n",
    "        n_boxes = len(boxes['level'])\n",
    "        for i in range(n_boxes):\n",
    "            (x,y,w,h) = (boxes['left'][i],boxes['top'][i],boxes['width'][i],boxes['height'][i])\n",
    "            cv2.rectangle(out_frame, (x,y), (x+w,y+h), (0,255,0), 2)   \n",
    "\n",
    "\n",
    "    #display frame\n",
    "    cv2.putText(out_frame, hold, (50,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,225,0), 2, cv2.LINE_AA)\n",
    "    cv2.imshow('Camera', out_frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mphy0049_g6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
